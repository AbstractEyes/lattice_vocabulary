"""
SYMBOLIC CAPTION SYNTHESIZER - USAGE GUIDE
===========================================

The synthesizer generates semantically coherent captions using tree-aware
composition with direct BulkCaptions data access.

PACKAGE STRUCTURE
-----------------
geovocab2.data.prompt.
├── symbolic_tree.py              - Tree structure and navigation
├── bulk_caption_data.py          - Data singleton (BulkCaptions)
└── symbolic_caption_synthesizer.py - Caption generation


BASIC USAGE
-----------

from geovocab2.data.prompt.symbolic_caption_synthesizer import (
    SymbolicCaptionSynthesizer,
    SymbolicCaptionFactory
)
from transformers import AutoTokenizer

# Load tokenizer
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")

# Create synthesizer
synthesizer = SymbolicCaptionFactory.create_synthesizer(
    tokenizer=tokenizer,
    use_tree=True,
    segment_length=77
)

# Generate a caption
caption = synthesizer.synthesize(
    complexity=3,
    composition_mode='tree_aware'
)

print(caption.to_text())
# Output: "<subject> [PAD] person standing wearing shirt in bright lighting"


COMPOSITION MODES
-----------------

1. TREE_AWARE (Recommended)
   Uses CategoryTreeNavigator for semantic coherence.

   caption = synthesizer.synthesize(
       primary_category="<subject>",
       complexity=3,
       composition_mode='tree_aware'
   )

   Features:
   - Follows hierarchical relationships
   - Uses compatibility scoring
   - Builds semantic chains
   - Pulls actual BulkCaptions data

2. MULTI_DOMAIN
   Composes across multiple semantic domains.

   caption = synthesizer.synthesize(
       complexity=2,
       composition_mode='multi_domain',
       domains=['subject', 'human', 'context']
   )

   Features:
   - Cross-domain mixing
   - Domain-aware operators
   - High compatibility filtering

3. CATEGORY
   Single category with BulkCaptions data.

   caption = synthesizer.synthesize(
       primary_category="<pose>",
       complexity=1,
       composition_mode='category'
   )

   Features:
   - Direct data access
   - Simple composition
   - Fast generation

4. ASSOCIATION
   Uses pre-composed semantic triples from FULL_ASSOCIATIVE.

   caption = synthesizer.synthesize(
       complexity=2,
       composition_mode='association'
   )

   Features:
   - Pre-validated triples
   - Logic operators
   - Rich semantic content

5. SPATIAL
   Focuses on spatial relationships.

   caption = synthesizer.synthesize(
       primary_category="<subject>",
       complexity=3,
       composition_mode='spatial'
   )

   Features:
   - Spatial relations (next to, on top of, beneath)
   - Scene composition
   - Object positioning

6. HYBRID
   Combines multiple strategies adaptively.

   caption = synthesizer.synthesize(
       complexity=3,
       composition_mode='hybrid'
   )

   Features:
   - Adaptive composition
   - Fallback strategies
   - Balanced complexity


BATCH GENERATION
----------------

# Generate multiple captions
batch = synthesizer.synthesize_batch(
    batch_size=32,
    complexity=2,
    composition_mode='tree_aware'
)

for caption in batch:
    print(caption.to_text())

# With category distribution
category_dist = {
    "<subject>": 0.4,
    "<pose>": 0.3,
    "<emotion>": 0.2,
    "<lighting>": 0.1
}

batch = synthesizer.synthesize_batch(
    batch_size=32,
    complexity=3,
    composition_mode='tree_aware',
    category_distribution=category_dist
)


INFINITE GENERATION (FOR TRAINING)
-----------------------------------

# Infinite generator for training loops
generator = synthesizer.yield_infinite(
    complexity=3,
    composition_mode='tree_aware'
)

for epoch in range(num_epochs):
    for step in range(steps_per_epoch):
        caption = next(generator)
        # Use caption for training


USAGE TRACKING
--------------

from geovocab2.data.prompt.symbolic_caption_synthesizer import UsageAccumulator

# Track token usage to prevent oversaturation
accumulator = UsageAccumulator(max_usage_ratio=0.3)

for i in range(10000):
    caption = synthesizer.synthesize(complexity=3)

    # Check if caption should be accepted
    if accumulator.should_accept(caption, threshold=0.7):
        accumulator.record(caption)
        # Use this caption
    else:
        # Reject and try again
        continue

# Get statistics
stats = accumulator.get_stats()
print(f"Total generations: {stats['total_generations']}")
print(f"Unique words: {stats['unique_words']}")
print(f"Oversaturated tokens: {stats['oversaturated_count']}")


TRAINING DATA PREPARATION
-------------------------

# Generate batch
batch = synthesizer.synthesize_batch(batch_size=32, complexity=3)

# Prepare for training
training_data = synthesizer.prepare_for_training(batch)

# training_data contains:
# - input_ids: (batch_size, segment_length) numpy array
# - attention_mask: (batch_size, segment_length) numpy array
# - categories: List of primary categories
# - shunts: List of shunt tokens

# Use with PyTorch
import torch

input_ids = torch.tensor(training_data['input_ids'])
attention_mask = torch.tensor(training_data['attention_mask'])

outputs = model(input_ids=input_ids, attention_mask=attention_mask)


PYTORCH DATASET
---------------

from geovocab2.data.prompt.symbolic_caption_synthesizer import (
    SymbolicCaptionFactory
)
from torch.utils.data import DataLoader

# Create dataset
dataset = SymbolicCaptionFactory.create_pytorch_dataset(
    tokenizer=tokenizer,
    num_samples=10000,
    complexity=3,
    composition_mode='tree_aware'
)

# Create dataloader
dataloader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=False,  # Already randomized
    num_workers=4
)

# Training loop
for batch in dataloader:
    input_ids = batch['input_ids']
    attention_mask = batch['attention_mask']
    categories = batch['category']

    # Train model
    outputs = model(input_ids=input_ids, attention_mask=attention_mask)
    loss = criterion(outputs, targets)
    loss.backward()


ADVANCED FEATURES
-----------------

1. TARGET TOKEN LENGTH

   caption = synthesizer.synthesize(
       complexity=3,
       target_tokens=150  # Will expand until reaching 150 tokens
   )

2. CUSTOM NAVIGATOR

   from geovocab2.data.prompt.symbolic_tree import CategoryTreeNavigator

   navigator = CategoryTreeNavigator()

   synthesizer = SymbolicCaptionSynthesizer(
       tokenizer=tokenizer,
       navigator=navigator,
       segment_length=77
   )

3. CAPTION METADATA

   caption = synthesizer.synthesize(complexity=3, composition_mode='tree_aware')

   # Access metadata
   if 'tree_chain' in caption.root.metadata:
       print(f"Composition chain: {caption.root.metadata['tree_chain']}")

   # Categories used
   print(f"Categories: {caption.categories_used}")

   # Token count
   print(f"Tokens: {caption.total_tokens}")

4. SEGMENT ACCESS

   segments = caption.get_segments(
       tokenizer=synthesizer.tokenizer,
       segment_length=77
   )

   for seg in segments:
       print(f"Tokens: {seg['tokens']}")
       print(f"Token IDs: {seg['token_ids']}")
       print(f"Category: {seg['category']}")


COMPOSITION PIPELINE
--------------------

The synthesizer uses this pipeline:

1. CategoryTreeNavigator
   - Provides tree structure and relationships
   - Scores compatibility between categories
   - Suggests composition partners
   - Accesses BulkCaptions data

2. SymbolicComposer
   - Implements composition strategies
   - Applies logic operators
   - Builds semantic trees
   - Uses actual BulkCaptions data

3. SymbolicCaptionSynthesizer
   - Orchestrates generation
   - Manages tokenization
   - Handles batching
   - Prepares training data

4. UsageAccumulator
   - Tracks token frequencies
   - Prevents oversaturation
   - Provides acceptance filtering


EXAMPLE: COMPLETE TRAINING SETUP
---------------------------------

from geovocab2.data.prompt.symbolic_caption_synthesizer import (
    SymbolicCaptionSynthesizer,
    UsageAccumulator,
    SymbolicCaptionFactory
)
from transformers import AutoTokenizer
from torch.utils.data import DataLoader
import torch

# Setup
tokenizer = AutoTokenizer.from_pretrained("bert-base-uncased")
synthesizer = SymbolicCaptionFactory.create_synthesizer(tokenizer)
accumulator = UsageAccumulator(max_usage_ratio=0.3)

# Dataset
dataset = SymbolicCaptionFactory.create_pytorch_dataset(
    tokenizer=tokenizer,
    num_samples=100000,
    complexity=3,
    composition_mode='tree_aware'
)

dataloader = DataLoader(
    dataset,
    batch_size=32,
    num_workers=4
)

# Training loop with oversaturation filtering
model = YourModel()
optimizer = torch.optim.Adam(model.parameters())

for epoch in range(num_epochs):
    for batch in dataloader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)

        # Forward pass
        outputs = model(input_ids=input_ids, attention_mask=attention_mask)
        loss = criterion(outputs, targets)

        # Backward pass
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        # Track usage (optional)
        for text in batch['text']:
            # Create mock caption for tracking
            # (In real use, you'd track during generation)
            pass


SPECIAL TOKENS AND SHUNTS
--------------------------

The synthesizer uses BulkCaptions special tokens:

Special Tokens (26 total):
  <subject>, <subject1>, <subject2>
  <pose>, <emotion>
  <upper_clothing>, <lower_clothing>, <footwear>
  <accessory>, <jewelry>, <headwear>
  <hair_style>, <hair_length>
  <background>, <material>, <fabric>
  <texture>, <pattern>, <lighting>
  <style>, <intent>, <color>, <size>
  <grid>, <zone>

Shunt Tokens (26 total):
  [SHUNT_1000000] through [SHUNT_1000025]

Each special token is paired with a shunt token for model conditioning.


PERFORMANCE TIPS
----------------

1. Use tree_aware mode for best semantic coherence
2. Adjust complexity based on desired caption length
3. Use UsageAccumulator for long training runs
4. Batch generation is faster than individual synthesis
5. PyTorch dataset with num_workers > 0 for parallelism
6. Infinite generator is most efficient for training
7. Pre-create synthesizer once and reuse


TROUBLESHOOTING
---------------

Q: Captions are nonsensical
A: Use composition_mode='tree_aware' and increase complexity

Q: Too much repetition
A: Use UsageAccumulator with threshold=0.7

Q: Captions too short
A: Increase complexity or use target_tokens parameter

Q: Generation too slow
A: Use synthesize_batch() or infinite generator

Q: Out of memory
A: Reduce batch_size or segment_length

Q: No BulkCaptions data appearing
A: Check that CategoryTreeNavigator is initialized correctly


REFERENCES
----------

- symbolic_tree.py: Tree structure and navigation
- bulk_caption_data.py: Data singleton
- SYMBOLIC_TREE_USAGE.md: Tree navigation guide
"""